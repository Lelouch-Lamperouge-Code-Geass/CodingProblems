### When Array is better than HashMap?


### abstract class vs interface

##### Interface

* interfaces can have no state or implementation  
* a class that implements an interface must provide an implementation of all the methods of that interface  

##### abstrct class

* abstract classes may contain state (data members) and/or implementation (methods)  
* abstract classes can be inherited without implementing the abstract methods (though such a derived class is abstract itself)  
* interfaces may be multiple-inherited, abstract classes may not (this is probably the key concrete reason for interfaces to exist separately from abtract classes - they permit an implementation of multiple inheritance that removes many of the problems of general MI). 


### TCP vs UDP

Transmission Control Protocol is a __connection-oriented protocol__, which means that it requires handshaking to set up end-to-end communications. Once a connection is set up, user data may be sent bi-directionally over the connection.

* Reliable – Strictly only at transport layer, TCP manages message acknowledgment, retransmission and timeout. Multiple attempts to deliver the message are made. If it gets lost along the way, the server will re-request the lost part. In TCP, there's either no missing data, or, in case of multiple timeouts, the connection is dropped. (This reliability however does not cover application layer, at which a separate acknowledgement flow control is still necessary)
* Ordered – If two messages are sent over a connection in sequence, the first message will reach the receiving application first. When data segments arrive in the wrong order, TCP buffers delay the out-of-order data until all data can be properly re-ordered and delivered to the application.
* Heavyweight – TCP requires three packets to set up a socket connection, before any user data can be sent. TCP handles reliability and congestion control.
* Streaming – Data is read as a byte stream, no distinguishing indications are transmitted to signal message (segment) boundaries.
* TCP is a protocol for communication between __exactly two endpoints__. It can't be used for broadcast and multicast.

User Datagram Protocol is a simpler message-based __connectionless protocol__. Connectionless protocols do not set up a dedicated end-to-end connection. Communication is achieved by transmitting information in one direction from source to destination without verifying the readiness or state of the receiver.

* Unreliable – When a UDP message is sent, it cannot be known if it will reach its destination; it could get lost along the way. There is no concept of acknowledgment, retransmission, or timeout.
* Not ordered – If two messages are sent to the same recipient, the order in which they arrive cannot be predicted.
* Lightweight – There is no ordering of messages, no tracking connections, etc. It is a small transport layer designed on top of IP.
* Datagrams – Packets are sent individually and are checked for integrity only if they arrive. Packets have definite boundaries which are honored upon receipt, meaning a read operation at the receiver socket will yield an entire message as it was originally sent.
* No congestion control – UDP itself does not avoid congestion. Congestion control measures must be implemented at the application level.
* Broadcasts - being connectionless, UDP can broadcast - sent packets can be addressed to be receivable by all devices on the subnet.

### socket

Here's a most basic explanation. A socket is defined by an IP address plus a port number. A server listens on a socket for client requests.
 
So, you could write a server that opens a socket connection on your development machine (localhost or IP address 127.0.0.1) on port 80 (default port). If, for example, the server was using the HTTP protocol, then a client could send a request to http://localhost. If the server were listening on port 3000 instead, then the client could send a request to http://localhost:3000.

Sockets are the interface between application layer and transport layers of OSI layer model. It is like a door through which you can go outside and come inside. Similarly, a packet is transferred to application layer from transport layer and vice versa. Every socket has a unique port number. So whenever a client wants to connect to server it must know the port of the socket and ip address. 
Every web application has a socket through which they interact with outer world by sending and receiving packets. The socket residing in server is known as server socket. The socket residing at client side is known as client socket.

 Remember that we need to bind a port number and ip address to server socket but in client socket it is not compulsory. Kernel of the client machine does it for the client.

Let us discuss socket programming. Socket programming is a way of creating sockets for server and for client. There are two major transport layer protocols known as TCP and UDP. Both of these protocols follow different procedure and provide different kind of services so we need to mention specifically inside the socket. There are many system calls and functions through which we can create sockets successfully. I will describe some of them. At server side you require functions like socket(), bind(), listen(), accept(), recvfrom(),sendto() etc.

### Character encoding

Characters that are needed for a specific purpose are grouped into a character set (also called a repertoire). (To refer to characters in an unambiguous way, each character is associated with a number, called a code point.)

The characters are stored in the computer as one or more bytes.

Basically, you can visualise this by assuming that all characters are stored in computers using a special code, like the ciphers used in espionage. A character encoding provides a key to unlock (ie. crack) the code. It is a set of mappings between the bytes in the computer and the characters in the character set. Without the key, the data looks like garbage.

The misleading term charset is often used to refer to what are in reality character encodings. You should be aware of this usage, but stick to using the term character encodings whenever you can.

So, when you input text using a keyboard or in some other way, the character encoding maps characters you choose to specific bytes in computer memory, and then to display the text it reads the bytes back into characters.


In computing, a character encoding is used to represent a repertoire of characters by some kind of encoding system. Depending on the abstraction level and context, corresponding code points and the resulting code space may be regarded as bit patterns, octets, natural numbers, electrical pulses, etc. A character encoding is used in computation, data storage, and transmission of textual data. "Character set", "character map", "codeset" and "code page" are related, but not identical, terms.

Early character codes associated with the optical or electrical telegraph could only represent a subset of the characters used in written languages, sometimes restricted to upper case letters, numerals and some punctuation only. The low cost of digital representation of data in modern computer systems allows more elaborate character codes (such as Unicode) which represent most of the characters used in many written languages. Character encoding using internationally accepted standards permits worldwide interchange of text in electronic form.

###  float representation

The two most common floating-point binary storage formats used by Intel processors were created for Intel and later standardized by the IEEE organization:

* IEEE Short Real: 32 bits	1 bit for the sign, 8 bits for the exponent, and 23 bits for the mantissa. Also called single precision.
* IEEE Long Real: 64 bits	1 bit for the sign, 11 bits for the exponent, and 52 bits for the mantissa. Also called double precision.


![alt](https://ryanstutorials.net/binary-tutorial/img/floating_point.png)

* https://ryanstutorials.net/binary-tutorial/binary-floating-point.php

